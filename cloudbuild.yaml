steps:
  # Stage 1: Install dependencies
  - name: 'python:3.10'
    id: 'install-deps'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üì¶ Installing dependencies..."
        pip install --upgrade pip
        pip install -r requirements.txt
        echo "‚úÖ Done"

  # Stage 2: Validate components
  - name: 'python:3.10'
    id: 'validate'
    waitFor: ['install-deps']
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üîç Validating components..."
        ls -la components/
        echo "‚úÖ Components validated"

  # Stage 3: Compile pipeline
  - name: 'python:3.10'
    id: 'compile'
    waitFor: ['validate']
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üì¶ Compiling pipeline..."
        pip install kfp
        cd pipelines
        python house_price_pipeline.py || python churn_pipeline.py
        
        # Verify JSON is valid
        python -m json.tool *.json > /dev/null && echo "‚úÖ Pipeline JSON valid" || echo "‚ùå Invalid JSON"
        
        ls -lh *.json
        echo "‚úÖ Compiled"

  # Stage 4: Submit to Vertex AI
  - name: 'python:3.10'
    id: 'submit'
    waitFor: ['compile']
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üöÄ Submitting pipeline to Vertex AI..."
        
        # Install Vertex AI SDK with pipeline support
        pip install "google-cloud-aiplatform[pipelines]"
        
        # Find pipeline JSON
        PIPELINE_FILE=$$(ls pipelines/*.json | head -1)
        echo "Pipeline: $$PIPELINE_FILE"
        
        # Submit pipeline using Python
        python3 << 'PYEOF'
        from google.cloud import aiplatform
        import os
        import glob
        
        # Get variables from Cloud Build
        PROJECT_ID = os.environ['PROJECT_ID']
        REGION = os.environ.get('_REGION', 'us-central1')
        BUCKET_NAME = os.environ.get('_BUCKET_NAME', f"{PROJECT_ID}-bucket")
        SHORT_SHA = os.environ.get('SHORT_SHA', 'latest')
        
        print(f"Project: {PROJECT_ID}")
        print(f"Region: {REGION}")
        print(f"Bucket: {BUCKET_NAME}")
        
        # Find pipeline file
        pipeline_files = glob.glob('pipelines/*.json')
        if not pipeline_files:
            print("‚ùå No pipeline JSON found!")
            exit(1)
        
        PIPELINE_FILE = pipeline_files[0]
        print(f"Using: {PIPELINE_FILE}")
        
        # Initialize Vertex AI
        aiplatform.init(project=PROJECT_ID, location=REGION)
        
        # Create and submit pipeline job
        job = aiplatform.PipelineJob(
            display_name=f"mlops-cicd-{SHORT_SHA}",
            template_path=PIPELINE_FILE,
            pipeline_root=f"gs://{BUCKET_NAME}/pipeline_root",
            parameter_values={
                "project_id": PROJECT_ID,
                "region": REGION,
                "bucket_name": BUCKET_NAME,
                "model_name": "house-price-model",
                "endpoint_name": "house-price-endpoint"
            },
            enable_caching=False
        )
        
        job.submit()
        
        print(f"‚úÖ Pipeline submitted!")
        print(f"Job: {job.resource_name}")
        print(f"üîó View: https://console.cloud.google.com/vertex-ai/locations/{REGION}/pipelines/runs?project={PROJECT_ID}")
        PYEOF

  # Stage 5: Notify
  - name: 'bash'
    id: 'notify'
    waitFor: ['submit']
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "=============================="
        echo "‚úÖ CI/CD Pipeline Complete!"
        echo "=============================="
        echo "Build: ${BUILD_ID}"
        echo "Commit: ${SHORT_SHA}"
        echo "Project: ${PROJECT_ID}"
        echo "Region: ${_REGION}"
        echo "=============================="

# Custom substitutions (must start with _)
substitutions:
  _REGION: 'us-central1'
  _BUCKET_NAME: '${PROJECT_ID}-mlops'

options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'
  substitution_option: 'ALLOW_LOOSE'

timeout: '1800s'
